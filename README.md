# Curso TC3006 - Inteligencia Artificial Avanzada para la Ciencia de Datos

## Integrantes del equipo 
* Luis Ángel Guzmán Iribe - A01741757
* Julian Lawrence Gil Soares - A00832272
* Alberto H Orozco Ramos - A00831719

## Profesores
* Ivan Mauricio Amaya Contreras
* Blanca Rosa Ruiz Hernandez
* Antonio Carlos Bento
* Frumencio Olivas Alvarez
* Hugo Terashima Marín

## Reto Periodo 1: Titanic - Machine Learning para el Desastre

Durante las diversas etapas de desarrollo de este proyecto, que abarcan desde la identificación de la problemática hasta el análisis y preparación de los requisitos y los datos correspondientes, así como el establecimiento de algoritmos de Machine Learning, su codificación, revisión e implementación, se persigue alcanzar una resolución satisfactoria, precisa y coherente basada en los recursos proporcionados. Esto se logrará mediante el uso de modelos matemáticos y estadísticos válidos que respalden y otorguen mayor veracidad a los datos generados por nuestro modelo.

Adicionalmente, se tiene como objetivo la implementación de herramientas y bibliotecas, como Pandas, Matplotlib y otras, para respaldar la visualización de los resultados obtenidos, teniendo en cuenta las tesis desarrolladas de manera teórica, asegurando así su coherencia y viabilidad.

En las etapas finales del primer proyecto, se anticipa que el modelo de Machine Learning brindará resultados cercanos a los datos reales, habiendo aplicado los métodos más óptimos para su implementación.

Carpetas en este repositorio:

* Momento de Retroalimentación: Reto Limpieza del Conjunto de Datos: Dentro de esta carpeta encontrarán el primer entregable de nuestro equipo para el reto del Titanic. Tenemos un Jupyter Notebook donde describimos y justificamos nuestro proceso de limpiar los datos así como los datos que nos quedaron después del proceso de limpieza.
* * <a href="https://github.com/4lb3rt0r/TC3006_Equipo2/tree/main/retro/Limpieza%20de%20Datos">Limpieza de Datos

## Files for revision
Following is a list of the files that must be checked for grading each subcompetency: 

* *Module 1: Statistics*
	* *SMA0101A*
		* **Evidence 01: Modeling** Please review file **final/M1_Statistics/Ev_01/dummyFile.txt**
* *Module 2: Machine Learning*
	* *SMA0401A*
		* **Evidence 01: ML from scratch** Please review file **final/M2_ML/Ev_01/dummyFile.txt**
		* **Evidence 02: ML from a framework** Please review file **final/M2_ML/Ev_02/dummyFolder/dummyFile.txt**


## Requested changes and replies
Following is a list of the location of the issues that were raised by the reviewer during the feedback phase. Please refer to them for more details.

* *Module 1: Statistics*
	* *SMA0101A*
		* **Evidence 01: Modeling: final/M1_Statistics/README.md**
* *Module 2: Machine Learning*
	* *SMA0401A*
		* **Evidence 01: ML from scratch: final/M2_ML/README.md**
		* **Evidence 02: ML from a framework: final/M2_ML/README.md**
* *Momento de Retroalimentación - Reto: Limpieza del Conjunto de Datos*
	* *Carpeta <a href="https://github.com/4lb3rt0r/TC3006_Equipo2/tree/main/retro/Limpieza%20de%20Datos">Limpieza de Datos</a>*
		* **Archivo README: <a href="https://github.com/4lb3rt0r/TC3006_Equipo2/blob/main/retro/Limpieza%20de%20Datos/README.md">retro/Limpieza de Datos/README.md</a>**
 		* **Código en Jupyter Notebook de Limpieza de Datos: <a href="https://github.com/4lb3rt0r/TC3006_Equipo2/blob/main/retro/Limpieza%20de%20Datos/clean_training_data.ipynb">retro/Limpieza de Datos/clean_training_data.ipynb</a>**
		* **Archivo CSV de la Base de Datos del Titanic (Kaggle): <a href="https://github.com/4lb3rt0r/TC3006_Equipo2/blob/main/retro/Limpieza%20de%20Datos/train.csv">retro/Limpieza de Datos/train.csv</a>**
		* **Output CSV de la Base de Datos del Titanic limpia: <a href="https://github.com/4lb3rt0r/TC3006_Equipo2/blob/main/retro/Limpieza%20de%20Datos/train_clean.csv">retro/Limpieza de Datos/train_clean.csv</a>**


See you!
